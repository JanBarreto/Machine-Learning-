import pandas as pd
from sklearn import preprocessing




Data = pd.read_csv("MalwareData.csv", sep="|")

legit = Data[0:41323].drop(["legitimate"], axis=1)
mal = Data[41323::].drop(["legitimate"], axis=1)

print("The shape of the legit dataset is: % samples, %s features"%(legit.shape[0],legit.shape[1]))
print("The shape of the malware dataset is: % samples, %s features"%(mal.shape[0],mal.shape[1]))

####################################
#we will see that the columns or fields for 56 variables

Data = pd.read_csv("MalwareData.csv", header = None, sep="|")
#0 malware 1 legitimate
print(Data)
print(Data.columns)

#################################
#feature name, assign a field name to a number for better feature representation.

Data = pd.read_csv("MalwareData.csv", sep="|")

print(Data.columns)
print(Data.describe())

##################################
#print the first top samples from data set

print(Data.head(5))
#############################
#print 57 colums-feature with the values
pd.set_option("display.max_columns", None)
print(Data.head(5))

#################################
#Decision tree learning(Tree Classifier)
#escoge las caracteristicas de las que considera mas importantes

from sklearn.ensemble import ExtraTreesClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.model_selection import train_test_split

# from sklearn import cross validation
from sklearn.model_selection import cross_validate

#3 columnas Name, md5, legitimate

data_in = Data.drop(['Name', 'md5', 'legitimate'], axis=1).values
labels = Data['legitimate'].values
extratrees = ExtraTreesClassifier().fit(data_in, labels)
select = SelectFromModel(extratrees, prefit=True)
data_in_new = select.transform(data_in)
print(data_in.shape, data_in_new.shape)
##############################################
#forma de decir que el numero real es 11, en este ejemplo
# el algoritmo selecciona que 11 son las caracteristicas mas importantes
#loop para que features recorra todas las funciones

import numpy as np
features = data_in_new.shape[1]
importances = extratrees.feature_importances_
indices = np.argsort(importances)[::-1]

for f in range(features):
    print("%d"%(f+1), Data.columns[2+indices[f]], importances[indices[f]])
####################################
#Random Forest, split data into four subsets the legit training, legit test mobile training and malware test
from sklearn.ensemble import RandomForestClassifier
# from sklearn.model_selection import cross_val_score
#from sklearn.model_selection import train_test_split
# import sklearn
#from sklearn.feature_selection import SelectFromModel
#from sklearn.ensemble import ExtraTreesClassifier
# from sklearn.model_selection import train_test_split
# from sklearn import cross_validation
#from sklearn.model_selection import cross_validate

#legit_train, legit_test, mal_train, mal_test = cross_validation.train_test_split(data_in_new, labels, test_size=0.2)
#classif =  RandomForestClassifier(n_estimators=50)
legit_train, legit_test, mal_train, mal_test = train_test_split(data_in_new, labels, test_size=0.2)
classif =  RandomForestClassifier(n_estimators=50)

classif.fit(legit_train,mal_train)


print(classif.score(legit_test,mal_test)*100) 
